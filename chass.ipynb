{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction\n",
    "\n",
    "**Made by  :** \n",
    "  - Enggar Kristian \n",
    "  - Wahyudi\n",
    "\n",
    "**Batch : FTDS - 012** \n",
    "\n",
    "**Objective : Final project, model Machine Learning for chatbot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library that will be used in this project\n",
    "\n",
    "# Library for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Library for preprocessing\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Library for modelling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from util import JSONParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Library for model evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from folders\n",
    "path = \"D:\\Bootcamp Data Science Batch 011 - Hacktiv8\\Final Project\\p2---final-project-ftds-012-group-003\\data\\intents.json\"\n",
    "\n",
    "# Defining JSONParser\n",
    "jp = JSONParser()\n",
    "\n",
    "# Parsing data intents\n",
    "jp.parse(path)\n",
    "\n",
    "# Building dataframe and save it to variable df\n",
    "df = jp.get_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data intents.json made by us for conversation between costumer and chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat_input</th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hei</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hy</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>bisa akses dimana</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>info lengkap perusahaan dimana min?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>apakah ada webnya</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>profile bank nya dimana ya?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>spill websitenya kak?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              chat_input  intents\n",
       "0                                    Hai    salam\n",
       "1                                   Halo    salam\n",
       "2                                  Hello    salam\n",
       "3                                    Hei    salam\n",
       "4                                     Hy    salam\n",
       "..                                   ...      ...\n",
       "486                    bisa akses dimana  website\n",
       "487  info lengkap perusahaan dimana min?  website\n",
       "488                    apakah ada webnya  website\n",
       "489          profile bank nya dimana ya?  website\n",
       "490                spill websitenya kak?  website\n",
       "\n",
       "[491 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into sample chat\n",
    "sample_chat = df.chat_input[430]\n",
    "sample_chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the chat into lowercase\n",
    "chat_lower = sample_chat.lower()\n",
    "chat_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove punctuations from the chat\n",
    "chat_punct = chat_lower.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "chat_punct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to change non-alphabetical characters with spaces too to make the data cleaner.\n",
    "chat_punct = re.sub(\"[^A-Za-z\\s']\",\" \", chat_punct)\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove tab, in case the customer is mistype inputting tab on their chat\n",
    "chat_punct = chat_punct.strip()\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining Stemmer\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "# Applying stemmer to the chat\n",
    "output   = stemmer.stem(chat_punct)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to case folding corpus in the dataframe\n",
    "def document_processing(document):\n",
    "    # Transform Document Into Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Remove Punctuation From Document\n",
    "    document = document.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "    # Remove Digit From Document\n",
    "    document = re.sub(\"[^A-Za-z\\s']\",\" \", document)\n",
    "\n",
    "    # Remove links\n",
    "    document = re.sub(r'http\\S+', '', document) # remove links\n",
    "    document = re.sub(r\"www.\\S+\", \" \", document) # remove link\n",
    "    \n",
    "    # Remove Tab From Document\n",
    "    document = document.strip()\n",
    "\n",
    "    #Stemmer\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "    # stemming process\n",
    "    document = stemmer.stem(document)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make function for subtitute all equation for cleaning data text, and stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between data (X) and target (y)\n",
    "X = df.chat_input\n",
    "y = df.intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Preprocessing text with Case Folding Function\n",
    "X_proc = X.apply(document_processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function cleaning text to the data set, and apply to all string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define text Vectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Vectorization from tensorflow use to convert string to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set shape      : (392, 392)\n",
      "Test-Set shape       : (99, 99)\n"
     ]
    }
   ],
   "source": [
    "# Split Data for Train-Set and Test-Set\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X_proc, y,test_size=0.2, random_state=5)\n",
    "print(f\"Train-Set shape      : {len(X_train),len(y_train)}\")\n",
    "print(f\"Test-Set shape       : {len(X_test),len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB Pipeline\n",
    "nb = make_pipeline(CountVectorizer(),\n",
    "                   MultinomialNB())\n",
    "\n",
    "# Training\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define with model machine learning Multinomial Naive Bayes with pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enggar\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:29:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=2,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=60,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=5, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "xgb = make_pipeline(CountVectorizer(),\n",
    "                   XGBClassifier(random_state=5, learning_rate=0.1, max_depth=2, n_estimators=60))\n",
    "\n",
    "# Training\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our favourite model Machine Learning that is Extreme Gradient Boosting. Uprgade from ensemble learning and latest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Pipeline\n",
    "dt = make_pipeline(CountVectorizer(),\n",
    "                   DecisionTreeClassifier())\n",
    "\n",
    "# Training\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline model Decision Tree for eficiency running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Multinomial Naive Bayes model accuracy(in %): 95.91836734693877\n",
      "Test-Set Multinomial Naive Bayes model accuracy(in %) : 83.83838383838383\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_nb = nb.predict(X_train)\n",
    "y_test_pred_nb = nb.predict(X_test)\n",
    "print(\"Train-Set Multinomial Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_train_pred_nb, y_train)*100)\n",
    "print(\"Test-Set Multinomial Naive Bayes model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_nb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a great result, from a dataset that is not much but the MultinomialNB model can read it well, so that it gets optimal results for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Decision Tree model accuracy(in %): 98.9795918367347\n",
      "Test-Set Decision Tree model accuracy(in %) : 75.75757575757575\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_dt = dt.predict(X_train)\n",
    "y_test_pred_dt = dt.predict(X_test)\n",
    "print(\"Train-Set Decision Tree model accuracy(in %):\", metrics.accuracy_score(y_train_pred_dt, y_train)*100)\n",
    "print(\"Test-Set Decision Tree model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_dt, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is not better than the MultinomialNB model, we can see that the model brings overfit results and is far below MultinomialNB for the test data results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Random Forest model accuracy(in %): 76.53061224489795\n",
      "Test-Set Random Forest model accuracy(in %) : 64.64646464646465\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb = xgb.predict(X_train)\n",
    "y_test_pred_xgb = xgb.predict(X_test)\n",
    "print(\"Train-Set Random Forest model accuracy(in %):\", metrics.accuracy_score(y_train_pred_xgb, y_train)*100)\n",
    "print(\"Test-Set Random Forest model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_xgb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oops, the favorite model actually doesn't study the text data model well, the results are the worst among the other 2 models, but goodfit, the data inference will not use the XGBoost model later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Model Saving\n",
    "\n",
    "Well, in the end, based on the results, we chose the MultinomialNB model to be a machine learning model that will be applied to chatbots in the banking industry, to add and satisfy service to customers who have complaints on Twitter later, then this chatbot will be active if customers chat via Direct Message on our official account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving Random Forest\n",
    "with open('model_2.pkl', 'wb') as file:\n",
    "  pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Building Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anda Terhubung dengan chatbot Kami, panggil aja CHASS\n",
      "Saya : hai\n",
      "Bot  : Hai kakak!\n",
      "\n",
      "Saya : atm\n",
      "Bot  : Oke kak jangan khawatir, untuk ATM rusak, ATM tertelan, dan ATM hilang akan kami ganti dengan kartu yang baru serta Gratis! Oiya jangan lupa isi data diri dulu ya di link ini https:/www.banktoyib.com/data_diri\n",
      "\n",
      "Saya : cara buat akun\n",
      "Bot  : Baik kak, pendaftaran akun rekening cukup mudah hanya masukkan email yang aktif, lalu buat password, jangan lupa siapkan dokumen diri seperti KTP dan NPWP, setelah itu pengenalan wajah, isi data diri, Selamat! Akun rekening kamu telah jadi.\n",
      "\n",
      "Saya : \n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\n",
      "Saya : \n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\n",
      "Saya : \n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\n",
      "Saya : \n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\n",
      "Saya : \n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\n",
      "Saya : \n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\n",
      "Saya : kamu siapa?\n",
      "Bot  : Tugas Chass untuk menjawab pertanyaan kakak seputar permasalahan banking anda seperti daftar akun, dan penggunaan aplikasi.\n",
      "\n",
      "Saya : \n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\n"
     ]
    }
   ],
   "source": [
    "print(\"Hai kakak, saat ini kamu tehubung dengan akun bisnis resmi Bank T0yip. Pesan ini akan dibalas oleh Costumer Handler Assitant atau kamu bisa panggil Chass :)\")\n",
    "while True:\n",
    "    # input user\n",
    "    chat = input(\"Saya : \")\n",
    "    # Preprocessing\n",
    "    chat_processed = document_processing(chat)\n",
    "    # Intent prediction (tag)\n",
    "    res = nb.predict_proba([chat_processed])\n",
    "    # get the probability value and its location\n",
    "    max_prob = max(res[0])\n",
    "    max_idx = np.argmax(res[0])\n",
    "    \n",
    "    # Define condition for unknown input\n",
    "    print(\"Saya :\",chat)\n",
    "    if max_prob < 0.20:\n",
    "        print(\"Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\")\n",
    "    # Define condition to give response towards specific tag\n",
    "    else:\n",
    "        print(f\"Bot  : {jp.get_response(nb.classes_[max_idx])}\\n\")\n",
    "    # Define response to end the chat for tag \"menutup\"\n",
    "    if nb.classes_[max_idx] == 'menutup':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has successfully made, and can apply to API Twitter Direct Message!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3313081f939a1cd2fc9e524e93ad175a39774b1d821a5d0f007e3e4c61533bad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
