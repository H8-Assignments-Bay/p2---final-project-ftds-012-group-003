{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction\n",
    "\n",
    "**Made by  :** \n",
    "  - Enggar Kristian \n",
    "  - Wahyudi\n",
    "\n",
    "**Batch : FTDS - 012** \n",
    "\n",
    "**Objective : Final project, model Machine Learning for chatbot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library that will be used in this project\n",
    "\n",
    "# Library for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Library for preprocessing\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Library for modelling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from util import JSONParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Library for model evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "# import for verification Name, email, and OTP\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from folders\n",
    "path = \"D:\\Bootcamp Data Science Batch 011 - Hacktiv8\\Final Project\\p2---final-project-ftds-012-group-003\\data\\intents.json\"\n",
    "\n",
    "# Defining JSONParser\n",
    "jp = JSONParser()\n",
    "\n",
    "# Parsing data intents\n",
    "jp.parse(path)\n",
    "\n",
    "# Building dataframe and save it to variable df\n",
    "df = jp.get_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data intents.json made by us for conversation between costumer and chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat_input</th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hei</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hy</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>bisa akses dimana</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>info lengkap perusahaan dimana min?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>apakah ada webnya</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>profile bank nya dimana ya?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>spill websitenya kak?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              chat_input  intents\n",
       "0                                    Hai    salam\n",
       "1                                   Halo    salam\n",
       "2                                  Hello    salam\n",
       "3                                    Hei    salam\n",
       "4                                     Hy    salam\n",
       "..                                   ...      ...\n",
       "523                    bisa akses dimana  website\n",
       "524  info lengkap perusahaan dimana min?  website\n",
       "525                    apakah ada webnya  website\n",
       "526          profile bank nya dimana ya?  website\n",
       "527                spill websitenya kak?  website\n",
       "\n",
       "[528 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dimana terdekat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into sample chat\n",
    "sample_chat = df.chat_input[430]\n",
    "sample_chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dimana terdekat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the chat into lowercase\n",
    "chat_lower = sample_chat.lower()\n",
    "chat_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dimana terdekat'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove punctuations from the chat\n",
    "chat_punct = chat_lower.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "chat_punct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dimana terdekat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to change non-alphabetical characters with spaces too to make the data cleaner.\n",
    "chat_punct = re.sub(\"[^A-Za-z\\s']\",\" \", chat_punct)\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dimana terdekat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove tab, in case the customer is mistype inputting tab on their chat\n",
    "chat_punct = chat_punct.strip()\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mana dekat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining Stemmer\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "# Applying stemmer to the chat\n",
    "output   = stemmer.stem(chat_punct)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to case folding corpus in the dataframe\n",
    "def document_processing(document):\n",
    "    # Transform Document Into Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Remove Punctuation From Document\n",
    "    document = document.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "    # Remove Digit From Document\n",
    "    document = re.sub(\"[^A-Za-z\\s']\",\" \", document)\n",
    "\n",
    "    # Remove links\n",
    "    document = re.sub(r'http\\S+', '', document) # remove links\n",
    "    document = re.sub(r\"www.\\S+\", \" \", document) # remove link\n",
    "    \n",
    "    # Remove Tab From Document\n",
    "    document = document.strip()\n",
    "\n",
    "    #Stemmer\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "    # stemming process\n",
    "    document = stemmer.stem(document)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make function for subtitute all equation for cleaning data text, and stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between data (X) and target (y)\n",
    "X = df.chat_input\n",
    "y = df.intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Preprocessing text with Case Folding Function\n",
    "X_proc = X.apply(document_processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function cleaning text to the data set, and apply to all string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define text Vectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Vectorization from scikit learn use to convert string to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set shape      : (422, 422)\n",
      "Test-Set shape       : (106, 106)\n"
     ]
    }
   ],
   "source": [
    "# Split Data for Train-Set and Test-Set\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X_proc, y,test_size=0.2, random_state=5)\n",
    "print(f\"Train-Set shape      : {len(X_train),len(y_train)}\")\n",
    "print(f\"Test-Set shape       : {len(X_test),len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB Pipeline\n",
    "nb = make_pipeline(CountVectorizer(),\n",
    "                   MultinomialNB())\n",
    "\n",
    "# Training\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define with model machine learning Multinomial Naive Bayes with pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enggar\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:11:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=2,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=60,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=5, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "xgb = make_pipeline(CountVectorizer(),\n",
    "                   XGBClassifier(random_state=5, learning_rate=0.1, max_depth=2, n_estimators=60))\n",
    "\n",
    "# Training\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our favourite model Machine Learning that is Extreme Gradient Boosting. Uprgade from ensemble learning and latest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Pipeline\n",
    "dt = make_pipeline(CountVectorizer(),\n",
    "                   DecisionTreeClassifier())\n",
    "\n",
    "# Training\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline model Decision Tree for eficiency running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Multinomial Naive Bayes model accuracy(in %): 95.73459715639811\n",
      "Test-Set Multinomial Naive Bayes model accuracy(in %) : 81.13207547169812\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_nb = nb.predict(X_train)\n",
    "y_test_pred_nb = nb.predict(X_test)\n",
    "print(\"Train-Set Multinomial Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_train_pred_nb, y_train)*100)\n",
    "print(\"Test-Set Multinomial Naive Bayes model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_nb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a great result, from a dataset that is not much but the MultinomialNB model can read it well, so that it gets optimal results for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Decision Tree model accuracy(in %): 98.81516587677726\n",
      "Test-Set Decision Tree model accuracy(in %) : 73.58490566037736\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_dt = dt.predict(X_train)\n",
    "y_test_pred_dt = dt.predict(X_test)\n",
    "print(\"Train-Set Decision Tree model accuracy(in %):\", metrics.accuracy_score(y_train_pred_dt, y_train)*100)\n",
    "print(\"Test-Set Decision Tree model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_dt, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is not better than the MultinomialNB model, we can see that the model brings overfit results and is far below MultinomialNB for the test data results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Random Forest model accuracy(in %): 70.85308056872039\n",
      "Test-Set Random Forest model accuracy(in %) : 67.9245283018868\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb = xgb.predict(X_train)\n",
    "y_test_pred_xgb = xgb.predict(X_test)\n",
    "print(\"Train-Set Random Forest model accuracy(in %):\", metrics.accuracy_score(y_train_pred_xgb, y_train)*100)\n",
    "print(\"Test-Set Random Forest model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_xgb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oops, the favorite model actually doesn't study the text data model well, the results are the worst among the other 2 models, but goodfit, the data inference will not use the XGBoost model later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Model Saving\n",
    "\n",
    "Well, in the end, based on the results, we chose the MultinomialNB model to be a machine learning model that will be applied to chatbots in the banking industry, to add and satisfy service to customers who have complaints on Twitter later, then this chatbot will be active if customers chat via Direct Message on our official account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving Random Forest\n",
    "with open('model_2.pkl', 'wb') as file:\n",
    "  pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Building Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number for OTP verification\n",
    "def OTP(nomor_rekening):\n",
    "    digits= nomor_rekening\n",
    "    OTP=\"\"\n",
    "    for i in range(6):\n",
    "        OTP+=digits[math.floor(random.random()*10)]\n",
    "        otp = OTP + \" is your OTP\"\n",
    "        msg= otp\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'552573 is your OTP'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OTP(\"3275032705981005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hai kakak, saat ini kamu tehubung dengan akun bisnis resmi Bank T0yip. Pesan ini akan dibalas oleh Costumer Handler Assitant atau kamu bisa panggil Chass :)\n",
      "Saya : ganti\n",
      "Bot  : Oke kak jangan khawatir, untuk penggantian kartu ATM rusak, kartu ATM tertelan, dan kartu ATM hilang kakak bisa menggantinya di kantor cabang terdekat atau bisa Chass bantu kakak, namun akan dikenakan biaya tambahan untuk materai 10000 sebesar Rp10.000 pembayarannya akan otomatis dipotong melalui kartu bank untuk penggantian kartu lama dengan kartu yang baru, dengan cara ketik #gantiATM untuk melanjutkan proses penggantiannya.\n",
      "\n",
      "Saya : #gantiATM\n",
      "Bot  : Maaf Kak, aku masih gak ngerti maksud kakak :(\n",
      "Baik kak aku bantu proses pergantian ATM ya, Sebelumnya ada beberapa syarat yang harus dilengkapi yaitu dengan isi data diri berikut:\n",
      "Masukkan nama lengkap Anda: \n",
      "\n",
      "Masukkan email Anda:\n",
      "\n",
      "Masukkan nomor handphone Anda:\n",
      "\n",
      "Masukkan nomor rekening Anda: \n",
      "\n",
      "\n",
      "HATI-HATI PENIPUAN! JANGAN BERIKAN OTP ke siapapun \n",
      "Kode OTP Anda: 4964. Silakan gunakan untuk melanjutkan proses transaksi.\n",
      "\n",
      "Masukkan 4 digit kode OTP Anda: \n",
      "Kode OTP yang Anda masukkan salah!\n",
      "Kode OTP yang Anda masukkan salah!\n",
      "Kode OTP yang Anda masukkan salah!\n",
      "Kode OTP yang Anda masukkan salah!\n",
      "Selamat kakak akan menerima kartu ATM baru! Tunggu kami ya kak maksimal 3x24 jam kartu ATM baru kakak sampai rumah.\n",
      "\n",
      "\n",
      "Ada lagi yang bisa Chess bantu kak?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hai kakak, saat ini kamu tehubung dengan akun bisnis resmi Bank T0yip. Pesan ini akan dibalas oleh Costumer Handler Assitant atau kamu bisa panggil Chass :)\")\n",
    "while True:\n",
    "    # input user\n",
    "    chat = input(\"Saya : \")\n",
    "    # Preprocessing\n",
    "    chat_processed = document_processing(chat)\n",
    "    # Intent prediction (tag)\n",
    "    res = nb.predict_proba([chat_processed])\n",
    "    # get the probability value and its location\n",
    "    max_prob = max(res[0])\n",
    "    max_idx = np.argmax(res[0])\n",
    "    \n",
    "    print(\"Saya :\",chat)\n",
    "    # Define condition for unknown input\n",
    "    if max_prob < 0.20:\n",
    "        print(\"Bot  : Maaf Kak, aku masih gak ngerti maksud kakak :(\")\n",
    "    # Define condition to give response towards specific tag\n",
    "    else:\n",
    "        print(f\"Bot  : {jp.get_response(nb.classes_[max_idx])}\\n\")\n",
    "\n",
    "    # Define solving #gantiATm\n",
    "    if chat == '#gantiATM':\n",
    "        print(\"Baik kak aku bantu proses pergantian ATM ya, Sebelumnya ada beberapa syarat yang harus dilengkapi yaitu dengan isi data diri berikut:\")\n",
    "        print(\"Masukkan nama lengkap Anda: \")\n",
    "        while True:\n",
    "            nama = input(\"Nama:\")\n",
    "            if len(nama) <= 1:\n",
    "                print(\"Kolom nama tidak boleh kosong.\")\n",
    "            else:\n",
    "                print(\"\\nMasukkan email Anda:\")\n",
    "                break\n",
    "        while True:\n",
    "            Email = input(\"Email: \")\n",
    "            if \"@\" not in Email:\n",
    "                print(\"Email anda salah tidak ada '@' di dalamnya\\n\")\n",
    "            elif \".\" not in Email:\n",
    "                print(\"Email anda salah tidak ada '.' di dalamnya\\n\")\n",
    "            else:    \n",
    "                print(\"\\nMasukkan nomor handphone Anda:\")\n",
    "                break    \n",
    "        no_hp = int(input(\"Nomor handphone: \"))\n",
    "        print(\"\\nMasukkan nomor rekening Anda: \")\n",
    "        while True:\n",
    "            no_rek = input(\"Nomor rekekning minimal 10 digit: \")\n",
    "            if len(no_rek) <= 8:\n",
    "                print(\"Nomor rekening Anda salah!\")\n",
    "            else:\n",
    "                print(\"\\n\")\n",
    "                break\n",
    "        no_otp = no_rek\n",
    "        while True:\n",
    "            # Define random OTP code\n",
    "            OTP=\"\"\n",
    "            for i in range(4):\n",
    "                OTP+=no_otp[math.floor(random.random()*10)]\n",
    "            else:\n",
    "                print(f\"HATI-HATI PENIPUAN! JANGAN BERIKAN OTP ke siapapun \\nKode OTP Anda: {OTP}. Silakan gunakan untuk melanjutkan proses transaksi.\\n\") \n",
    "                print(\"Masukkan 4 digit kode OTP Anda: \")\n",
    "            while True:    \n",
    "                input_otp = input(\"Kode OTP 4 digit: \")\n",
    "                if input_otp != OTP:\n",
    "                    print(f\"Kode OTP yang Anda masukkan salah!\")\n",
    "                else:\n",
    "                    print(\"Selamat kakak akan menerima kartu ATM baru! Tunggu kami ya kak maksimal 3x24 jam kartu ATM baru kakak sampai rumah.\\n\")\n",
    "                    break\n",
    "            print(\"\\nAda lagi yang bisa Chess bantu kak?\")\n",
    "            break\n",
    "        \n",
    "    # Define response to end the chat for tag \"penutup\"\n",
    "    if nb.classes_[max_idx] == 'penutup':\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has successfully made, and can apply to API Twitter Direct Message!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3313081f939a1cd2fc9e524e93ad175a39774b1d821a5d0f007e3e4c61533bad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
