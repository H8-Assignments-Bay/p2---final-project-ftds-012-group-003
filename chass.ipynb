{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library that will be used in this project\n",
    "\n",
    "# Library for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Library for preprocessing\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Library for modelling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from util import JSONParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Library for model evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from folders\n",
    "path = \"D:\\Bootcamp Data Science Batch 011 - Hacktiv8\\Final Project\\p2---final-project-ftds-012-group-003\\data\\intents.json\"\n",
    "\n",
    "# Defining JSONParser\n",
    "jp = JSONParser()\n",
    "\n",
    "# Parsing data intents\n",
    "jp.parse(path)\n",
    "\n",
    "# Building dataframe and save it to variable df\n",
    "df = jp.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat_input</th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hei</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hy</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>bisa akses dimana</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>info lengkap perusahaan dimana min?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>apakah ada webnya</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>profile bank nya dimana ya?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>spill websitenya kak?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              chat_input  intents\n",
       "0                                    Hai    salam\n",
       "1                                   Halo    salam\n",
       "2                                  Hello    salam\n",
       "3                                    Hei    salam\n",
       "4                                     Hy    salam\n",
       "..                                   ...      ...\n",
       "486                    bisa akses dimana  website\n",
       "487  info lengkap perusahaan dimana min?  website\n",
       "488                    apakah ada webnya  website\n",
       "489          profile bank nya dimana ya?  website\n",
       "490                spill websitenya kak?  website\n",
       "\n",
       "[491 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Look into sample chat\n",
    "sample_chat = df.chat_input[430]\n",
    "sample_chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the chat into lowercase\n",
    "chat_lower = sample_chat.lower()\n",
    "chat_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Remove punctuations from the chat\n",
    "chat_punct = chat_lower.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "chat_punct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to change non-alphabetical characters with spaces too to make the data cleaner.\n",
    "chat_punct = re.sub(\"[^A-Za-z\\s']\",\" \", chat_punct)\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove tab, in case the customer is mistype inputting tab on their chat\n",
    "chat_punct = chat_punct.strip()\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boleh ketemu langsung'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining Stemmer\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "# Applying stemmer to the chat\n",
    "output   = stemmer.stem(chat_punct)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to case folding corpus in the dataframe\n",
    "def document_processing(document):\n",
    "    # Transform Document Into Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Remove Punctuation From Document\n",
    "    document = document.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "    # Remove Digit From Document\n",
    "    document = re.sub(\"[^A-Za-z\\s']\",\" \", document)\n",
    "\n",
    "    # Remove links\n",
    "    document = re.sub(r'http\\S+', '', document) # remove links\n",
    "    document = re.sub(r\"www.\\S+\", \" \", document) # remove link\n",
    "    \n",
    "    # Remove Tab From Document\n",
    "    document = document.strip()\n",
    "\n",
    "    #Stemmer\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "    # stemming process\n",
    "    document = stemmer.stem(document)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between data (X) and target (y)\n",
    "X = df.chat_input\n",
    "y = df.intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Preprocessing text with Case Folding Function\n",
    "X_proc = X.apply(document_processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3.3. Word Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define text Vectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set shape      : (392, 392)\n",
      "Test-Set shape       : (99, 99)\n"
     ]
    }
   ],
   "source": [
    "# Split Data for Train-Set and Test-Set\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X_proc, y,test_size=0.2, random_state=5)\n",
    "print(f\"Train-Set shape      : {len(X_train),len(y_train)}\")\n",
    "print(f\"Test-Set shape       : {len(X_test),len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB Pipeline\n",
    "nb = make_pipeline(CountVectorizer(),\n",
    "                   MultinomialNB())\n",
    "\n",
    "# Training\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enggar\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=2,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=60,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=5, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "xgb = make_pipeline(CountVectorizer(),\n",
    "                   XGBClassifier(random_state=5, learning_rate=0.1, max_depth=2, n_estimators=60))\n",
    "\n",
    "# Training\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Pipeline\n",
    "dt = make_pipeline(CountVectorizer(),\n",
    "                   DecisionTreeClassifier())\n",
    "\n",
    "# Training\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Model Evaluation for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Multinomial Naive Bayes model accuracy(in %): 95.91836734693877\n",
      "Test-Set Multinomial Naive Bayes model accuracy(in %) : 83.83838383838383\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_nb = nb.predict(X_train)\n",
    "y_test_pred_nb = nb.predict(X_test)\n",
    "print(\"Train-Set Multinomial Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_train_pred_nb, y_train)*100)\n",
    "print(\"Test-Set Multinomial Naive Bayes model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_nb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Model Evaluation for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Decision Tree model accuracy(in %): 98.9795918367347\n",
      "Test-Set Decision Tree model accuracy(in %) : 73.73737373737373\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_dt = dt.predict(X_train)\n",
    "y_test_pred_dt = dt.predict(X_test)\n",
    "print(\"Train-Set Decision Tree model accuracy(in %):\", metrics.accuracy_score(y_train_pred_dt, y_train)*100)\n",
    "print(\"Test-Set Decision Tree model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_dt, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3. Model Evaluation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Random Forest model accuracy(in %): 76.53061224489795\n",
      "Test-Set Random Forest model accuracy(in %) : 64.64646464646465\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb = xgb.predict(X_train)\n",
    "y_test_pred_xgb = xgb.predict(X_test)\n",
    "print(\"Train-Set Random Forest model accuracy(in %):\", metrics.accuracy_score(y_train_pred_xgb, y_train)*100)\n",
    "print(\"Test-Set Random Forest model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_xgb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving Random Forest\n",
    "with open('model_2.pkl', 'wb') as file:\n",
    "  pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Building Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anda Terhubung dengan chatbot Kami, panggil aja CHASS\n",
      "Saya : web\n",
      "Bot  : satu-satunya website kami www.banktoyib.com ya kak, ada pengalaman luar biasa jika kaka mengunjunginya.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Anda Terhubung dengan chatbot Kami, panggil aja CHASS\")\n",
    "while True:\n",
    "    # input user\n",
    "    chat = input(\"Saya : \")\n",
    "    # Preprocessing\n",
    "    chat_processed = document_processing(chat)\n",
    "    # Intent prediction (tag)\n",
    "    res = nb.predict_proba([chat_processed])\n",
    "    # get the probability value and its location\n",
    "    max_prob = max(res[0])\n",
    "    max_idx = np.argmax(res[0])\n",
    "    \n",
    "    # Define condition for unknown input\n",
    "    print(\"Saya :\",chat)\n",
    "    if max_prob < 0.20:\n",
    "        print(\"Bot  : Maaf Kak, aku masih gak ngerti maksud kakak ):\")\n",
    "    # Define condition to give response towards specific tag\n",
    "    else:\n",
    "        print(f\"Bot  : {jp.get_response(nb.classes_[max_idx])}\\n\")\n",
    "    # Define response to end the chat for tag \"menutup\"\n",
    "    if nb.classes_[max_idx] == 'menutup':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3313081f939a1cd2fc9e524e93ad175a39774b1d821a5d0f007e3e4c61533bad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
